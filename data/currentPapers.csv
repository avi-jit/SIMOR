"id","title","summary","venue","year","authors","citationCount","referenceCount","influentialCitationCount","url"
"7dfbd4a728a78aaefc6415a7baf59694278bb942","Simulated Multiple Reference Training Improves Low-Resource Machine Translation","A novel MT training method is introduced that approximates the full space of possible translations by: sampling a paraphrase of the reference sentence from a paraphraser and training the MT model to predict the paraphrasers' distribution over possible tokens.","Conference on Empirical Methods in Natural Language Processing",2020,"Huda Khayrallah,Brian Thompson,Matt Post,Philipp Koehn",24,44,2,"https://www.semanticscholar.org/paper/7dfbd4a728a78aaefc6415a7baf59694278bb942"
"7d226921c29b32cd68b404b11c71f99b8dd65f7e","SMRT Chatbots: Improving Non-Task-Oriented Dialog with Simulated Multiple Reference Training","Simulated Multiple Reference Training is comparable to pretraining in human evaluation quality, and outperforms pretraining on automatic quality and lexical diversity, without requiring related-domain dialog data.","Conference on Empirical Methods in Natural Language Processing",2020,"Huda Khayrallah,Jo√£o Sedoc",3,46,0,"https://www.semanticscholar.org/paper/7d226921c29b32cd68b404b11c71f99b8dd65f7e"
"a86a303477ee91d66304e87d91a41471af056ec9","Learning to Generalize to More: Continuous Semantic Augmentation for Neural Machine Translation","A novel data augmentation paradigm termed Continuous Semantic Augmentation (CsaNMT), which augments each training instance with an adjacency semantic region that could cover adequate variants of literal expression under the same meaning, is presented.","Annual Meeting of the Association for Computational Linguistics",2022,"Xiangpeng Wei,Heng Yu,Yue Hu,Rongxiang Weng,Weihua Luo,Jun Xie,Rong Jin",12,75,0,"https://www.semanticscholar.org/paper/a86a303477ee91d66304e87d91a41471af056ec9"
"0025d6dd25836a82a6855c326d4dfa6cac561f8f","Paraphrase Generation as Zero-Shot Multilingual Translation: Disentangling Semantic Similarity from Lexical and Syntactic Diversity","A simple paraphrase generation algorithm which discourages the production of n-grams that are present in the input and which produces paraphrases that better preserve meaning and are more gramatical, for the same level of lexical diversity.","Conference on Machine Translation",2020,"Brian Thompson,Matt Post",36,50,1,"https://www.semanticscholar.org/paper/0025d6dd25836a82a6855c326d4dfa6cac561f8f"
"f2e15f3f2c3d4f7e8cf8445435e40d65d828ffd5","Data Augmentation for Low-Resource Neural Machine Translation","A novel data augmentation approach that targets low-frequency words by generating new sentence pairs containing rare words in new, synthetically created contexts that improves translation quality on simulated low-resource settings.","Annual Meeting of the Association for Computational Linguistics",2017,"Marzieh Fadaee,Arianna Bisazza,Christof Monz",369,21,23,"https://www.semanticscholar.org/paper/f2e15f3f2c3d4f7e8cf8445435e40d65d828ffd5"
"59c7687040245b36a079923f1fc55a889d47f227","Monotonic Simultaneous Translation with Chunk-wise Reordering and Refinement","An algorithm is proposed to reorder and refine the target side of a full sentence translation corpus, so that the words/phrases between the source and target sentences are aligned largely monotonically, using word alignment and non-autoregressive neural machine translation.","Conference on Machine Translation",2021,"HyoJung Han,Seokchan Ahn,Yoonjung Choi,Insoo Chung,Sangha Kim,Kyunghyun Cho",3,55,0,"https://www.semanticscholar.org/paper/59c7687040245b36a079923f1fc55a889d47f227"
"b4491aa9c5a906f060b5c9b6b24db3b11cd44238","Improved Statistical Machine Translation Using Paraphrases","This work shows how techniques from paraphrasing can be used to deal with otherwise unknown source language phrases and shows that augmenting a state-of-the-art SMT system with paraphrases leads to significantly improved coverage and translation quality.","North American Chapter of the Association for Computational Linguistics",2006,"Chris Callison-Burch,Philipp Koehn,M. Osborne",335,23,26,"https://www.semanticscholar.org/paper/b4491aa9c5a906f060b5c9b6b24db3b11cd44238"
"7ecf212e3ab4413dfea6a179f36565fe0d028616","Using Paraphrases for Parameter Tuning in Statistical Machine Translation","This paper introduces a new full-sentence paraphrase technique, based on English-to-English decoding with an MT system, and demonstrates that the resulting paraphrases can be used to drastically reduce the number of human reference translations needed for parameter tuning, without a significant decrease in translation quality.","WMT@ACL",2007,"Nitin Madnani,N. F. Ayan,P. Resnik,B. Dorr",90,27,3,"https://www.semanticscholar.org/paper/7ecf212e3ab4413dfea6a179f36565fe0d028616"
"ba8adc6bdb2dc0653597ecf728da5798c582ec19","Are Multiple Reference Translations Necessary? Investigating the Value of Paraphrased Reference Translations in Parameter Optimization","This analysis suggests that it is necessary to invest in four or more human translations in order to significantly improve on a single translation augmented by monolingual paraphrases.","Conference of the Association for Machine Translation in the Americas",2008,"Nitin Madnani,P. Resnik,B. Dorr,R. Schwartz",36,19,2,"https://www.semanticscholar.org/paper/ba8adc6bdb2dc0653597ecf728da5798c582ec19"
"e127e8d56bf179e5e311bcc933ae764308b3d417","Improved Statistical Machine Translation Using Monolingually-Derived Paraphrases","This work presents what is to their knowledge the first successful integration of a collocational approach to untranslated words with an end-to-end, state of the art SMT system demonstrating significant translation improvements in a low-resource setting.","Conference on Empirical Methods in Natural Language Processing",2009,"Yuval Marton,Chris Callison-Burch,P. Resnik",169,42,13,"https://www.semanticscholar.org/paper/e127e8d56bf179e5e311bcc933ae764308b3d417"
"86d84c1c9b0a500f930696ab27c83a4b30477560","Simple and Effective Paraphrastic Similarity from Parallel Translations","A model and methodology for learning paraphrastic sentence embeddings directly from bitext is presented, removing the time-consuming intermediate step of creating para-phrase corpora and is shown to be orders of magnitude faster than more complex state-of-the-art baselines.","Annual Meeting of the Association for Computational Linguistics",2019,"J. Wieting,Kevin Gimpel,Graham Neubig,Taylor Berg-Kirkpatrick",41,41,3,"https://www.semanticscholar.org/paper/86d84c1c9b0a500f930696ab27c83a4b30477560"
"101141b047d119ef9c8fda8dd83d3d9eb3fbfd1f","Improved Lexically Constrained Decoding for Translation and Monolingual Rewriting","","North American Chapter of the Association for Computational Linguistics",2019,"J. E. Hu,Huda Khayrallah,Ryan Culkin,Patrick Xia,Tongfei Chen,Matt Post,Benjamin Van Durme",99,48,10,"https://www.semanticscholar.org/paper/101141b047d119ef9c8fda8dd83d3d9eb3fbfd1f"
"7262bc3674c4c063526eaf4d2dcf54eecea7bf77","ParaNMT-50M: Pushing the Limits of Paraphrastic Sentence Embeddings with Millions of Machine Translations","This work uses ParaNMT-50M, a dataset of more than 50 million English-English sentential paraphrase pairs, to train paraphrastic sentence embeddings that outperform all supervised systems on every SemEval semantic textual similarity competition, in addition to showing how it can be used for paraphrase generation.","Annual Meeting of the Association for Computational Linguistics",2017,"J. Wieting,Kevin Gimpel",280,69,41,"https://www.semanticscholar.org/paper/7262bc3674c4c063526eaf4d2dcf54eecea7bf77"
"0ee468b9b709a2610c4b574d67218e7960350224","SwitchOut: an Efficient Data Augmentation Algorithm for Neural Machine Translation","An extremely simple data augmentation strategy for NMT: randomly replacing words in both the source sentence and the target sentence with other random words from their corresponding vocabularies is proposed.","Conference on Empirical Methods in Natural Language Processing",2018,"Xinyi Wang,Hieu Pham,Zihang Dai,Graham Neubig",167,26,22,"https://www.semanticscholar.org/paper/0ee468b9b709a2610c4b574d67218e7960350224"
"57a10537978600fd33dcdd48922c791609a4851a","Sequence-Level Knowledge Distillation","It is demonstrated that standard knowledge distillation applied to word-level prediction can be effective for NMT, and two novel sequence-level versions of knowledge distilling are introduced that further improve performance, and somewhat surprisingly, seem to eliminate the need for beam search.","Conference on Empirical Methods in Natural Language Processing",2016,"Yoon Kim,Alexander M. Rush",705,66,49,"https://www.semanticscholar.org/paper/57a10537978600fd33dcdd48922c791609a4851a"
"27902aaa105053b15b66ad2b3384b91734878edf","Improving Simultaneous Translation by Incorporating Pseudo-References with Fewer Reorderings","This work proposes a novel method that rewrites the target side of existing full-sentence corpora into simultaneous-style translation, and shows substantial improvements on Zh\rightarrowEn and Ja\ rightarrowEn simultaneous translation with the addition of these generated pseudo-references.","Conference on Empirical Methods in Natural Language Processing",2020,"Junkun Chen,Renjie Zheng,Atsuhito Kita,Mingbo Ma,Liang Huang",9,30,3,"https://www.semanticscholar.org/paper/27902aaa105053b15b66ad2b3384b91734878edf"
"9a716bf565445740f47243bfde06398ded224cb4","Multi-Reference Training with Pseudo-References for Neural Translation and Text Generation","This work investigates several different ways of utilizing multiple human references during training and proposes an algorithm to generate exponentially many pseudo-references by first compressing existing human references into lattices and then traversing them to generate new pseudo-References.","Conference on Empirical Methods in Natural Language Processing",2018,"Renjie Zheng,Mingbo Ma,Liang Huang",22,21,1,"https://www.semanticscholar.org/paper/9a716bf565445740f47243bfde06398ded224cb4"
"2730fad5b82aac0bdd76d72b5deb8d256b71f45b","Improving Simultaneous Translation with Pseudo References","This work proposes a novel method that rewrites the target side of existing full-sentence corpus into simultaneous-style translation, and demonstrates about +2.7 BLEU improvements with the addition of newly generated pseudo references.","ArXiv",2020,"Junkun Chen,Renjie Zheng,Atsuhito Kita,Mingbo Ma,Liang Huang",2,25,2,"https://www.semanticscholar.org/paper/2730fad5b82aac0bdd76d72b5deb8d256b71f45b"
"386f3fed6c4d3af27e6ff5e13263ac90ce085ba0","Improving data augmentation for low resource speech-to-text translation with diverse paraphrasing","A target-side data augmentation method for low-resource language speech translation which generates large-scale target- side paraphrases based on a paraphrase generation model which incorporates several statistical machine translation features and the commonly used recurrent neural network feature.","Neural Networks",2022,"Chenggang Mi,Lei Xie,Yanning Zhang",8,41,1,"https://www.semanticscholar.org/paper/386f3fed6c4d3af27e6ff5e13263ac90ce085ba0"
"8c331703728000f7e6ea6de0ad22b65afb9d3623","Bridging the Gap between Training and Inference: Multi-Candidate Optimization for Diverse Neural Machine Translation","This paper proposes a multi-candidate optimization framework to score the diversity and the quality of candidate translations during training, and optimize the diverse NMT model with two strate-gies based on reinforcement learning, namely hard constrained training and soft constrained training.","NAACL-HLT",2022,"Huan Lin,Baosong Yang,Liang Yao,Dayiheng Liu,Haibo Zhang,Jun Xie,M. Zhang,Jinsong Su",3,45,0,"https://www.semanticscholar.org/paper/8c331703728000f7e6ea6de0ad22b65afb9d3623"
"1743eb03ec333cf70e22f39e2cd45c61a0052ffc","Multi-Referenced Training for Dialogue Response Generation","This work first analyzes the training objective of dialogue models from the view of Kullback-Leibler divergence and shows that the gap between the real world probability distribution and the single-referenced data's probability distribution prevents the model from learning the one-to-many relations efficiently.","SIGDIAL Conferences",2020,"Tianyu Zhao,Tatsuya Kawahara",7,38,1,"https://www.semanticscholar.org/paper/1743eb03ec333cf70e22f39e2cd45c61a0052ffc"
"fb243dfd1234b8f76dfda740a62402663da74085","Exploring Data Augmentation for Code Generation Tasks","Focusing on data utilization for downstream tasks, this work proposes and adapt augmentation methods that yield consistent improvements in code translation and summarization by up to 6.9% and 7.5% respectively.","ArXiv",2023,"Pinzhen Chen,Gerasimos Lampouras",3,28,0,"https://www.semanticscholar.org/paper/fb243dfd1234b8f76dfda740a62402663da74085"